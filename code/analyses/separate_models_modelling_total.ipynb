{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math \n",
    "import seaborn as sns\n",
    "import matplotlib.colors as mcolors\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.formula.api import mixedlm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "import matplotlib.pyplot as mpl\n",
    "import matplotlib\n",
    "\n",
    "colors = list(mcolors.TABLEAU_COLORS.keys())*2\n",
    "\n",
    "parentDirectory = os.path.abspath(os.path.join(os.path.join(os.getcwd(), os.pardir), os.pardir))\n",
    "DATA_DIR = parentDirectory +'/data/'\n",
    "FIGURES_DIR = parentDirectory +'/figures/'\n",
    "\n",
    "full_names = {\n",
    "    'AU': 'Australia',\n",
    "    'BR': 'Brazil',\n",
    "    'CA': 'Canada',\n",
    "    'FR': 'France',\n",
    "    'DE': 'Germany',\n",
    "    'IN': 'India',\n",
    "    'IT': 'Italy',\n",
    "    'MX': 'Mexico',\n",
    "    'ES': 'Spain',\n",
    "    'GB': 'United Kingdom',\n",
    "    'US': 'United States',\n",
    "    'DK': 'Denmark'\n",
    "}\n",
    "\n",
    "event_dicts = [{'country': 'AU',\n",
    "  'start_md_1': '2020-03-27',\n",
    "  'end_md_1': '2020-06-07',\n",
    "  'start_md_2': np.nan},\n",
    " {'country': 'BR',\n",
    "  'start_md_1': '2020-03-23',\n",
    "  'end_md_1': '2020-08-09',\n",
    "  'start_md_2': np.nan},\n",
    " {'country': 'CA',\n",
    "  'start_md_1': '2020-03-19',\n",
    "  'end_md_1': '2020-06-21',\n",
    "  'start_md_2': '2020-10-12'},\n",
    " {'country': 'DE',\n",
    "  'start_md_1': '2020-03-21',\n",
    "  'end_md_1': '2020-05-09',\n",
    "  'start_md_2': '2020-12-18'},\n",
    " {'country': 'DK',\n",
    "  'start_md_1': '2020-03-17',\n",
    "  'end_md_1': '2020-05-07',\n",
    "  'start_md_2': np.nan},\n",
    " {'country': 'ES',\n",
    "  'start_md_1': '2020-03-17',\n",
    "  'end_md_1': '2020-06-14',\n",
    "  'start_md_2': '2020-11-07'},\n",
    " {'country': 'FR',\n",
    "  'start_md_1': '2020-03-18',\n",
    "  'end_md_1': '2020-06-08',\n",
    "  'start_md_2': '2020-11-01'},\n",
    " {'country': 'GB',\n",
    "  'start_md_1': '2020-03-23',\n",
    "  'end_md_1': '2020-08-03',\n",
    "  'start_md_2': '2020-10-21'},\n",
    " {'country': 'IN',\n",
    "  'start_md_1': '2020-03-24',\n",
    "  'end_md_1': '2020-10-29',\n",
    "  'start_md_2': np.nan},\n",
    " {'country': 'IT',\n",
    "  'start_md_1': '2020-03-11',\n",
    "  'end_md_1': '2020-06-06',\n",
    "  'start_md_2': '2020-11-06'},\n",
    " {'country': 'JP',\n",
    "  'start_md_1': '2020-04-12',\n",
    "  'end_md_1': '2020-05-30',\n",
    "  'start_md_2': np.nan},\n",
    " {'country': 'KE',\n",
    "  'start_md_1': '2020-03-24',\n",
    "  'end_md_1': '2020-10-04',\n",
    "  'start_md_2': np.nan},\n",
    " {'country': 'MX',\n",
    "  'start_md_1': '2020-03-25',\n",
    "  'end_md_1': '2020-10-06',\n",
    "  'start_md_2': np.nan},\n",
    " {'country': 'NG',\n",
    "  'start_md_1': '2020-03-27',\n",
    "  'end_md_1': '2020-08-09',\n",
    "  'start_md_2': np.nan},\n",
    " {'country': 'US',\n",
    "  'start_md_1': '2020-03-21',\n",
    "  'end_md_1': '2020-06-11',\n",
    "  'start_md_2': '2020-11-26'}]\n",
    "\n",
    "df_events = pd.DataFrame(event_dicts)\n",
    "\n",
    "df_events['start_md_1'] = pd.to_datetime(df_events['start_md_1'])\n",
    "df_events['end_md_1'] = pd.to_datetime(df_events['end_md_1'])\n",
    "df_events['start_md_2'] = pd.to_datetime(df_events['start_md_2'])\n",
    "\n",
    "df_agg = pd.read_pickle(DATA_DIR+'df_agg_cats.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helpers\n",
    "\n",
    "def generate_equation(order):\n",
    "    if order == 'Cubic':\n",
    "        eq = \"volume_total ~ intervention_flag*k*year + intervention_flag*np.power(k,2)*year + intervention_flag*np.power(k,3)*year\"\n",
    "    elif order == \"Quadratic\":\n",
    "        eq = \"volume_total ~ intervention_flag*k*year + intervention_flag*np.power(k,2)*year\"\n",
    "    elif order == \"Linear\":\n",
    "        eq = \"volume_total ~ intervention_flag*k*year\"\n",
    "    elif order == 'Constant':\n",
    "        eq = \"volume_total ~ intervention_flag*year\"\n",
    "    return eq\n",
    "\n",
    "def generate_equation_interactions(order):\n",
    "    if order == 'Cubic':\n",
    "        eq = \"volume_total ~ intervention_flag*k*year*C(country)*C(category) + intervention_flag*np.power(k,2)*year*C(country)*C(category) + intervention_flag*np.power(k,3)*year*C(country)*C(category)\"\n",
    "    elif order == \"Quadratic\":\n",
    "        eq = \"volume_total ~ intervention_flag*k*year*C(country)*C(category) + intervention_flag*np.power(k,2)*year*C(country)*C(category)\"\n",
    "    elif order == \"Linear\":\n",
    "        eq = \"volume_total ~ intervention_flag*k*year*C(country)*C(category)\"\n",
    "    elif order == 'Constant':\n",
    "        eq = \"volume_total ~ intervention_flag*year*C(country)*C(category)\"\n",
    "    return eq\n",
    "    \n",
    "def get_standard_error_sum(covariates):\n",
    "    '''\n",
    "    #95CI is approximated with +- 2 sum_variance_standard_error\n",
    "    '''\n",
    "    \n",
    "    #get the variance covariance matrix\n",
    "    vcov = result_interactions.cov_params()\\\n",
    "        .loc[covariates,covariates].values\n",
    "    \n",
    "    #calculate the sum of all pair wise covariances by summing up\n",
    "    m_sum = np.sum(vcov)\n",
    "    \n",
    "    #variance of a sum of variables is the square root\n",
    "    return np.sqrt((m_sum))\n",
    "\n",
    "def make_stars(val):\n",
    "    if val<0.0001:\n",
    "        return '****'\n",
    "    elif val<0.001:\n",
    "        return '***'\n",
    "    elif val<0.01:\n",
    "        return '**'\n",
    "    elif val<0.05:\n",
    "        return '*'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def make_star_ste(value,ste):\n",
    "    if value>0 and value-2*ste>0:\n",
    "        return '*'\n",
    "    elif value<0 and value+2*ste<0:\n",
    "        return '*'\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "weeks_2019 = list(df_agg.iloc[0]['volume_weekly_total'].index)[:52]\n",
    "weeks_2020 = list(df_agg.iloc[0]['volume_weekly_total'].index)[52:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for cnt, row in df_agg.iterrows():\n",
    "    start_md = df_events.loc[df_events['country'] == row['country']].iloc[0]['start_md_1']\n",
    "    end_md = df_events.loc[df_events['country'] == row['country']].iloc[0]['end_md_1']\n",
    "    start_md2 = df_events.loc[df_events['country'] == row['country']].iloc[0]['start_md_2']\n",
    "    \n",
    "    for week in zip(row['volume_weekly_total'].index,row['volume_weekly_total'].values,row['volume_percent_weekly_total'].values):\n",
    "        \n",
    "        entry = {}\n",
    "\n",
    "        entry['country'] = row['country']\n",
    "        entry['category'] = row['category']\n",
    "        \n",
    "\n",
    "        if week[0] in weeks_2020:\n",
    "            date = pd.to_datetime(week[0])\n",
    "\n",
    "            if type(start_md2)!=pd._libs.tslibs.nattype.NaTType and date > start_md2:\n",
    "                continue\n",
    "\n",
    "            entry['k'] = math.floor(((date - start_md).days +7) / 7)\n",
    "            entry['volume_total'] = week[1]\n",
    "            entry['volume_percent'] = week[2]\n",
    "            entry['year'] = '2020'\n",
    "            l.append(entry)\n",
    "\n",
    "        elif week[0] in weeks_2019:\n",
    "            date = pd.to_datetime(weeks_2020[weeks_2019.index(week[0])])\n",
    "            \n",
    "            if type(start_md2)!=pd._libs.tslibs.nattype.NaTType and date > start_md2:\n",
    "                continue\n",
    "\n",
    "            entry['k'] = math.floor(((date - start_md).days +7) / 7)\n",
    "            entry['volume_total'] = week[1]\n",
    "            entry['volume_percent'] = week[2]\n",
    "            entry['year'] = '2019'\n",
    "            l.append(entry)\n",
    "\n",
    "df = pd.DataFrame(l)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[(df['k'] >= -30) & (df['k'] <= 30)]\n",
    "df = df.loc[(df['country'].isin(list(full_names.keys())))]\n",
    "df['intervention_flag'] = df['k'].apply(lambda x: 1 if x >= 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = list(df['category'].unique())\n",
    "k = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df.loc[(df['k'] >= -k) & (df['k'] <= k)].copy()\n",
    "df_temp['volume_total'] = df_temp['volume_total'].apply(np.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries_list = []\n",
    "\n",
    "for name, group in df_temp.groupby(['country','category']):\n",
    "    entry = {}\n",
    "    \n",
    "    mod = smf.ols(generate_equation('Quadratic'), data = group)\n",
    "    res = mod.fit(cov_type='hc0')\n",
    "    \n",
    "    entry['country'] = name[0]\n",
    "    entry['category'] = name[1]\n",
    "    \n",
    "    entry['alpha'] = res.params['intervention_flag:year[T.2020]']\n",
    "    entry['ste'] = res.bse['intervention_flag:year[T.2020]']\n",
    "    entry['pval'] = res.pvalues['intervention_flag:year[T.2020]']\n",
    "    entry['r2'] = res.rsquared\n",
    "    \n",
    "    entries_list.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.DataFrame(entries_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>category</th>\n",
       "      <th>alpha</th>\n",
       "      <th>ste</th>\n",
       "      <th>pval</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AU</td>\n",
       "      <td>pastry and bakery product</td>\n",
       "      <td>0.519702</td>\n",
       "      <td>0.173019</td>\n",
       "      <td>2.666950e-03</td>\n",
       "      <td>0.856903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>BR</td>\n",
       "      <td>pastry and bakery product</td>\n",
       "      <td>0.909112</td>\n",
       "      <td>0.086046</td>\n",
       "      <td>4.308115e-26</td>\n",
       "      <td>0.928356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>CA</td>\n",
       "      <td>pastry and bakery product</td>\n",
       "      <td>1.256330</td>\n",
       "      <td>0.246688</td>\n",
       "      <td>3.528296e-07</td>\n",
       "      <td>0.808006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>DE</td>\n",
       "      <td>pastry and bakery product</td>\n",
       "      <td>0.960700</td>\n",
       "      <td>0.154088</td>\n",
       "      <td>4.525399e-10</td>\n",
       "      <td>0.871245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>DK</td>\n",
       "      <td>pastry and bakery product</td>\n",
       "      <td>0.428403</td>\n",
       "      <td>0.196029</td>\n",
       "      <td>2.885878e-02</td>\n",
       "      <td>0.553069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>ES</td>\n",
       "      <td>pastry and bakery product</td>\n",
       "      <td>1.446911</td>\n",
       "      <td>0.246645</td>\n",
       "      <td>4.454636e-09</td>\n",
       "      <td>0.862044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>FR</td>\n",
       "      <td>pastry and bakery product</td>\n",
       "      <td>1.315179</td>\n",
       "      <td>0.273901</td>\n",
       "      <td>1.573627e-06</td>\n",
       "      <td>0.816687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>GB</td>\n",
       "      <td>pastry and bakery product</td>\n",
       "      <td>1.097855</td>\n",
       "      <td>0.225667</td>\n",
       "      <td>1.144944e-06</td>\n",
       "      <td>0.927841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>IN</td>\n",
       "      <td>pastry and bakery product</td>\n",
       "      <td>1.053318</td>\n",
       "      <td>0.243026</td>\n",
       "      <td>1.463055e-05</td>\n",
       "      <td>0.744596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>IT</td>\n",
       "      <td>pastry and bakery product</td>\n",
       "      <td>1.084825</td>\n",
       "      <td>0.332984</td>\n",
       "      <td>1.122453e-03</td>\n",
       "      <td>0.842861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>MX</td>\n",
       "      <td>pastry and bakery product</td>\n",
       "      <td>-0.001196</td>\n",
       "      <td>0.098543</td>\n",
       "      <td>9.903189e-01</td>\n",
       "      <td>0.323979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>US</td>\n",
       "      <td>pastry and bakery product</td>\n",
       "      <td>1.055205</td>\n",
       "      <td>0.222031</td>\n",
       "      <td>2.009112e-06</td>\n",
       "      <td>0.828223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    country                   category     alpha       ste          pval  \\\n",
       "12       AU  pastry and bakery product  0.519702  0.173019  2.666950e-03   \n",
       "40       BR  pastry and bakery product  0.909112  0.086046  4.308115e-26   \n",
       "68       CA  pastry and bakery product  1.256330  0.246688  3.528296e-07   \n",
       "96       DE  pastry and bakery product  0.960700  0.154088  4.525399e-10   \n",
       "124      DK  pastry and bakery product  0.428403  0.196029  2.885878e-02   \n",
       "152      ES  pastry and bakery product  1.446911  0.246645  4.454636e-09   \n",
       "180      FR  pastry and bakery product  1.315179  0.273901  1.573627e-06   \n",
       "208      GB  pastry and bakery product  1.097855  0.225667  1.144944e-06   \n",
       "236      IN  pastry and bakery product  1.053318  0.243026  1.463055e-05   \n",
       "264      IT  pastry and bakery product  1.084825  0.332984  1.122453e-03   \n",
       "292      MX  pastry and bakery product -0.001196  0.098543  9.903189e-01   \n",
       "320      US  pastry and bakery product  1.055205  0.222031  2.009112e-06   \n",
       "\n",
       "           r2  \n",
       "12   0.856903  \n",
       "40   0.928356  \n",
       "68   0.808006  \n",
       "96   0.871245  \n",
       "124  0.553069  \n",
       "152  0.862044  \n",
       "180  0.816687  \n",
       "208  0.927841  \n",
       "236  0.744596  \n",
       "264  0.842861  \n",
       "292  0.323979  \n",
       "320  0.828223  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res.loc[df_res['category']=='pastry and bakery product']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beef dish &\n",
      "0.16[0.08], 0.79 &\n",
      "0.35[0.06], 0.82 &\n",
      "0.24[0.08], 0.63 &\n",
      "0.26[0.1], 0.4 &\n",
      "0.16[0.15], 0.39 &\n",
      "0.59[0.13], 0.7 &\n",
      "0.38[0.15], 0.68 &\n",
      "0.55[0.12], 0.77 &\n",
      "0.23[0.11], 0.64 &\n",
      "0.17[0.13], 0.39 &\n",
      "0.2[0.1], 0.66 &\n",
      "0.41[0.11], 0.66\n",
      "\\\\\n",
      "bread and flatbread &\n",
      "0.39[0.15], 0.91 &\n",
      "0.6[0.11], 0.96 &\n",
      "1.08[0.17], 0.9 &\n",
      "0.48[0.11], 0.93 &\n",
      "0.69[0.17], 0.88 &\n",
      "1.41[0.21], 0.91 &\n",
      "1.36[0.19], 0.9 &\n",
      "0.67[0.25], 0.96 &\n",
      "0.64[0.13], 0.8 &\n",
      "1.37[0.28], 0.86 &\n",
      "0.13[0.11], 0.92 &\n",
      "0.84[0.09], 0.92\n",
      "\\\\\n",
      "cheese &\n",
      "0.37[0.11], 0.74 &\n",
      "0.45[0.09], 0.85 &\n",
      "0.35[0.11], 0.68 &\n",
      "0.18[0.1], 0.8 &\n",
      "0.26[0.21], 0.52 &\n",
      "0.64[0.18], 0.65 &\n",
      "0.44[0.15], 0.6 &\n",
      "0.62[0.12], 0.76 &\n",
      "0.6[0.11], 0.89 &\n",
      "0.41[0.18], 0.64 &\n",
      "0.62[0.12], 0.66 &\n",
      "0.27[0.08], 0.66\n",
      "\\\\\n",
      "chicken dish &\n",
      "0.25[0.09], 0.84 &\n",
      "0.28[0.06], 0.91 &\n",
      "0.3[0.09], 0.81 &\n",
      "0.31[0.12], 0.77 &\n",
      "0.19[0.13], 0.65 &\n",
      "0.77[0.14], 0.87 &\n",
      "0.52[0.16], 0.67 &\n",
      "0.57[0.11], 0.82 &\n",
      "0.38[0.13], 0.79 &\n",
      "0.5[0.17], 0.81 &\n",
      "0.34[0.07], 0.91 &\n",
      "0.29[0.07], 0.83\n",
      "\\\\\n",
      "cocktail &\n",
      "0.25[0.16], 0.73 &\n",
      "0.35[0.21], 0.73 &\n",
      "0.29[0.09], 0.8 &\n",
      "0.06[0.12], 0.84 &\n",
      "-0.18[0.21], 0.79 &\n",
      "0.09[0.22], 0.74 &\n",
      "0.26[0.16], 0.77 &\n",
      "0.7[0.2], 0.72 &\n",
      "-0.23[0.19], 0.4 &\n",
      "0.5[0.23], 0.79 &\n",
      "-0.1[0.14], 0.51 &\n",
      "0.31[0.1], 0.66\n",
      "\\\\\n",
      "dessert &\n",
      "0.44[0.12], 0.79 &\n",
      "0.41[0.08], 0.89 &\n",
      "0.56[0.11], 0.83 &\n",
      "0.34[0.12], 0.71 &\n",
      "0.32[0.12], 0.69 &\n",
      "0.99[0.15], 0.9 &\n",
      "0.74[0.18], 0.81 &\n",
      "1.01[0.16], 0.85 &\n",
      "0.51[0.19], 0.76 &\n",
      "0.66[0.18], 0.85 &\n",
      "0.27[0.09], 0.88 &\n",
      "0.37[0.1], 0.72\n",
      "\\\\\n",
      "egg dish &\n",
      "0.82[0.27], 0.74 &\n",
      "0.24[0.17], 0.61 &\n",
      "0.23[0.17], 0.58 &\n",
      "0.29[0.15], 0.66 &\n",
      "0.14[0.19], 0.47 &\n",
      "0.73[0.18], 0.79 &\n",
      "0.58[0.19], 0.81 &\n",
      "0.55[0.18], 0.81 &\n",
      "0.55[0.12], 0.9 &\n",
      "0.33[0.29], 0.73 &\n",
      "0.34[0.1], 0.82 &\n",
      "0.21[0.2], 0.56\n",
      "\\\\\n",
      "fish dish &\n",
      "0.12[0.17], 0.44 &\n",
      "0.36[0.36], 0.38 &\n",
      "0.14[0.1], 0.66 &\n",
      "0.24[0.14], 0.5 &\n",
      "0.33[0.23], 0.22 &\n",
      "0.65[0.17], 0.55 &\n",
      "0.27[0.12], 0.57 &\n",
      "0.29[0.09], 0.79 &\n",
      "0.08[0.08], 0.68 &\n",
      "0.11[0.16], 0.31 &\n",
      "0.38[0.21], 0.61 &\n",
      "0.16[0.08], 0.85\n",
      "\\\\\n",
      "fruit &\n",
      "0.36[0.07], 0.87 &\n",
      "0.21[0.04], 0.8 &\n",
      "0.33[0.07], 0.9 &\n",
      "0.2[0.09], 0.79 &\n",
      "0.05[0.06], 0.61 &\n",
      "0.6[0.11], 0.83 &\n",
      "0.64[0.12], 0.77 &\n",
      "0.65[0.08], 0.94 &\n",
      "0.28[0.1], 0.83 &\n",
      "0.33[0.1], 0.78 &\n",
      "0.35[0.07], 0.93 &\n",
      "0.19[0.06], 0.89\n",
      "\\\\\n",
      "herb &\n",
      "0.03[0.09], 0.78 &\n",
      "0.05[0.05], 0.95 &\n",
      "0.21[0.07], 0.91 &\n",
      "0.16[0.12], 0.93 &\n",
      "0.45[0.18], 0.66 &\n",
      "0.16[0.08], 0.81 &\n",
      "0.19[0.14], 0.87 &\n",
      "0.58[0.1], 0.91 &\n",
      "0.17[0.08], 0.92 &\n",
      "0.27[0.14], 0.76 &\n",
      "-0.18[0.13], 0.71 &\n",
      "0.14[0.06], 0.92\n",
      "\\\\\n",
      "lamb dish &\n",
      "0.18[0.14], 0.82 &\n",
      "0.61[0.14], 0.71 &\n",
      "-0.04[0.17], 0.35 &\n",
      "0.05[0.11], 0.75 &\n",
      "0.13[0.45], 0.22 &\n",
      "-0.31[0.55], 0.08 &\n",
      "-0.32[0.15], 0.4 &\n",
      "0.31[0.26], 0.59 &\n",
      "-0.14[0.14], 0.47 &\n",
      "-0.37[0.24], 0.5 &\n",
      "-0.11[0.45], 0.18 &\n",
      "0.11[0.21], 0.34\n",
      "\\\\\n",
      "pasta, pizza and noodle dish &\n",
      "0.22[0.08], 0.8 &\n",
      "0.43[0.08], 0.78 &\n",
      "0.28[0.07], 0.82 &\n",
      "0.17[0.07], 0.63 &\n",
      "0.25[0.08], 0.4 &\n",
      "0.66[0.14], 0.77 &\n",
      "0.34[0.1], 0.65 &\n",
      "0.37[0.1], 0.91 &\n",
      "0.5[0.12], 0.88 &\n",
      "0.61[0.15], 0.72 &\n",
      "0.3[0.11], 0.77 &\n",
      "0.27[0.06], 0.68\n",
      "\\\\\n",
      "pastry and bakery product &\n",
      "0.52[0.17], 0.86 &\n",
      "0.91[0.09], 0.93 &\n",
      "1.26[0.25], 0.81 &\n",
      "0.96[0.15], 0.87 &\n",
      "0.43[0.2], 0.55 &\n",
      "1.45[0.25], 0.86 &\n",
      "1.32[0.27], 0.82 &\n",
      "1.1[0.23], 0.93 &\n",
      "1.05[0.24], 0.74 &\n",
      "1.08[0.33], 0.84 &\n",
      "-0.0[0.1], 0.32 &\n",
      "1.06[0.22], 0.83\n",
      "\\\\\n",
      "pie &\n",
      "0.37[0.16], 0.88 &\n",
      "0.49[0.15], 0.87 &\n",
      "0.8[0.19], 0.79 &\n",
      "0.3[0.31], 0.45 &\n",
      "0.58[0.19], 0.5 &\n",
      "1.14[0.22], 0.79 &\n",
      "0.74[0.18], 0.77 &\n",
      "0.75[0.14], 0.83 &\n",
      "0.31[0.13], 0.44 &\n",
      "0.84[0.28], 0.84 &\n",
      "0.65[0.26], 0.63 &\n",
      "0.66[0.26], 0.75\n",
      "\\\\\n",
      "pork dish &\n",
      "0.19[0.1], 0.85 &\n",
      "0.32[0.06], 0.88 &\n",
      "0.35[0.12], 0.59 &\n",
      "0.23[0.13], 0.43 &\n",
      "0.31[0.1], 0.28 &\n",
      "0.42[0.12], 0.69 &\n",
      "0.34[0.13], 0.76 &\n",
      "0.56[0.1], 0.85 &\n",
      "0.19[0.11], 0.83 &\n",
      "0.4[0.13], 0.53 &\n",
      "0.49[0.1], 0.81 &\n",
      "0.34[0.12], 0.61\n",
      "\\\\\n",
      "potato dish &\n",
      "0.33[0.13], 0.72 &\n",
      "0.46[0.15], 0.87 &\n",
      "0.53[0.19], 0.58 &\n",
      "0.47[0.11], 0.77 &\n",
      "0.01[0.26], 0.59 &\n",
      "0.61[0.13], 0.72 &\n",
      "0.59[0.15], 0.82 &\n",
      "0.66[0.11], 0.78 &\n",
      "0.63[0.09], 0.93 &\n",
      "0.47[0.19], 0.83 &\n",
      "1.11[0.28], 0.67 &\n",
      "0.44[0.12], 0.73\n",
      "\\\\\n",
      "rice dish &\n",
      "0.17[0.1], 0.75 &\n",
      "0.4[0.07], 0.74 &\n",
      "0.16[0.09], 0.66 &\n",
      "0.1[0.1], 0.73 &\n",
      "0.24[0.11], 0.5 &\n",
      "0.63[0.12], 0.68 &\n",
      "0.37[0.13], 0.75 &\n",
      "0.28[0.09], 0.87 &\n",
      "0.61[0.09], 0.89 &\n",
      "0.21[0.16], 0.54 &\n",
      "0.32[0.09], 0.85 &\n",
      "0.23[0.06], 0.85\n",
      "\\\\\n",
      "salad &\n",
      "0.18[0.15], 0.84 &\n",
      "0.11[0.09], 0.61 &\n",
      "0.04[0.06], 0.9 &\n",
      "0.16[0.12], 0.81 &\n",
      "-0.08[0.22], 0.79 &\n",
      "0.54[0.15], 0.89 &\n",
      "0.41[0.16], 0.85 &\n",
      "0.6[0.17], 0.81 &\n",
      "0.35[0.11], 0.39 &\n",
      "0.24[0.13], 0.8 &\n",
      "0.24[0.11], 0.64 &\n",
      "0.02[0.09], 0.85\n",
      "\\\\\n",
      "sandwich &\n",
      "0.25[0.1], 0.48 &\n",
      "0.04[0.11], 0.4 &\n",
      "-0.13[0.09], 0.5 &\n",
      "0.17[0.14], 0.31 &\n",
      "-0.09[0.24], 0.28 &\n",
      "0.26[0.18], 0.25 &\n",
      "0.25[0.22], 0.46 &\n",
      "0.14[0.13], 0.49 &\n",
      "0.33[0.13], 0.69 &\n",
      "0.34[0.24], 0.41 &\n",
      "0.18[0.13], 0.5 &\n",
      "-0.18[0.11], 0.36\n",
      "\\\\\n",
      "sauce &\n",
      "0.38[0.08], 0.84 &\n",
      "0.43[0.06], 0.86 &\n",
      "0.31[0.08], 0.8 &\n",
      "0.26[0.12], 0.72 &\n",
      "0.36[0.15], 0.6 &\n",
      "0.71[0.12], 0.81 &\n",
      "0.49[0.13], 0.69 &\n",
      "0.6[0.09], 0.86 &\n",
      "0.71[0.15], 0.9 &\n",
      "0.52[0.14], 0.57 &\n",
      "0.46[0.09], 0.84 &\n",
      "0.33[0.08], 0.85\n",
      "\\\\\n",
      "sausage &\n",
      "0.33[0.18], 0.72 &\n",
      "0.29[0.09], 0.77 &\n",
      "0.18[0.11], 0.54 &\n",
      "-0.01[0.18], 0.47 &\n",
      "0.15[0.26], 0.22 &\n",
      "0.77[0.12], 0.73 &\n",
      "0.36[0.11], 0.75 &\n",
      "0.55[0.1], 0.8 &\n",
      "0.81[0.18], 0.56 &\n",
      "0.38[0.17], 0.44 &\n",
      "0.27[0.12], 0.75 &\n",
      "0.34[0.05], 0.77\n",
      "\\\\\n",
      "snack &\n",
      "0.28[0.1], 0.56 &\n",
      "0.3[0.06], 0.75 &\n",
      "0.26[0.08], 0.78 &\n",
      "0.02[0.09], 0.64 &\n",
      "-0.11[0.15], 0.34 &\n",
      "0.13[0.12], 0.45 &\n",
      "0.37[0.11], 0.67 &\n",
      "0.57[0.09], 0.72 &\n",
      "0.43[0.13], 0.8 &\n",
      "0.18[0.16], 0.58 &\n",
      "0.08[0.09], 0.39 &\n",
      "0.32[0.08], 0.72\n",
      "\\\\\n",
      "soft drink &\n",
      "0.27[0.11], 0.54 &\n",
      "-0.05[0.05], 0.59 &\n",
      "-0.02[0.07], 0.48 &\n",
      "0.09[0.06], 0.82 &\n",
      "-0.04[0.18], 0.46 &\n",
      "0.47[0.15], 0.61 &\n",
      "0.04[0.09], 0.57 &\n",
      "0.32[0.11], 0.72 &\n",
      "-0.13[0.09], 0.64 &\n",
      "0.53[0.13], 0.41 &\n",
      "0.15[0.13], 0.49 &\n",
      "-0.02[0.06], 0.56\n",
      "\\\\\n",
      "soup &\n",
      "-0.11[0.11], 0.92 &\n",
      "0.5[0.18], 0.68 &\n",
      "0.27[0.11], 0.91 &\n",
      "0.12[0.11], 0.87 &\n",
      "0.22[0.12], 0.85 &\n",
      "0.5[0.1], 0.74 &\n",
      "0.34[0.14], 0.88 &\n",
      "0.29[0.1], 0.94 &\n",
      "0.34[0.09], 0.63 &\n",
      "0.23[0.15], 0.83 &\n",
      "0.31[0.11], 0.56 &\n",
      "0.25[0.09], 0.96\n",
      "\\\\\n",
      "spice &\n",
      "0.28[0.08], 0.84 &\n",
      "0.14[0.07], 0.94 &\n",
      "0.27[0.08], 0.85 &\n",
      "0.09[0.07], 0.78 &\n",
      "0.03[0.06], 0.57 &\n",
      "0.49[0.1], 0.78 &\n",
      "0.45[0.15], 0.77 &\n",
      "0.49[0.09], 0.85 &\n",
      "0.42[0.08], 0.95 &\n",
      "0.09[0.1], 0.34 &\n",
      "0.16[0.09], 0.89 &\n",
      "0.29[0.06], 0.82\n",
      "\\\\\n",
      "stew &\n",
      "0.23[0.14], 0.86 &\n",
      "0.55[0.2], 0.58 &\n",
      "0.48[0.16], 0.89 &\n",
      "0.41[0.16], 0.52 &\n",
      "0.59[0.26], 0.54 &\n",
      "0.57[0.19], 0.78 &\n",
      "0.08[0.14], 0.84 &\n",
      "0.43[0.13], 0.87 &\n",
      "0.55[0.13], 0.83 &\n",
      "0.39[0.3], 0.3 &\n",
      "0.5[0.27], 0.25 &\n",
      "0.61[0.13], 0.94\n",
      "\\\\\n",
      "vegetable and legume &\n",
      "0.29[0.08], 0.9 &\n",
      "0.21[0.07], 0.94 &\n",
      "0.28[0.09], 0.86 &\n",
      "0.22[0.15], 0.71 &\n",
      "0.34[0.12], 0.46 &\n",
      "0.51[0.12], 0.86 &\n",
      "0.69[0.14], 0.79 &\n",
      "0.57[0.11], 0.89 &\n",
      "0.53[0.07], 0.92 &\n",
      "0.27[0.16], 0.73 &\n",
      "0.4[0.09], 0.81 &\n",
      "0.3[0.07], 0.84\n",
      "\\\\\n",
      "wine, beer and liquor &\n",
      "0.13[0.05], 0.68 &\n",
      "0.19[0.08], 0.85 &\n",
      "0.1[0.05], 0.59 &\n",
      "0.02[0.07], 0.82 &\n",
      "-0.04[0.11], 0.68 &\n",
      "0.06[0.14], 0.64 &\n",
      "-0.29[0.05], 0.78 &\n",
      "0.33[0.08], 0.78 &\n",
      "0.18[0.13], 0.55 &\n",
      "-0.16[0.1], 0.53 &\n",
      "0.33[0.1], 0.52 &\n",
      "0.13[0.05], 0.45\n",
      "\\\\\n"
     ]
    }
   ],
   "source": [
    "for name, group in df_res.groupby(['category']):\n",
    "    print(name+' &')\n",
    "    c=0\n",
    "    for name1, group1 in group.groupby(['country']):\n",
    "        c+=1\n",
    "        if c ==12:\n",
    "            print(str(round(group1['alpha'].values[0],2))+ '['+str(round(group1['ste'].values[0],2))+\n",
    "              '], '+str(round(group1['r2'].values[0],2)))\n",
    "        else:\n",
    "            print(str(round(group1['alpha'].values[0],2))+ '['+str(round(group1['ste'].values[0],2))+\n",
    "              '], '+str(round(group1['r2'].values[0],2))+' &')\n",
    "    print('\\\\\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = pd.read_pickle(DATA_DIR+'modes_coarse.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for cnt, row in df_agg.iterrows():\n",
    "    start_md = df_events.loc[df_events['country'] == row['country']].iloc[0]['start_md_1']\n",
    "    end_md = df_events.loc[df_events['country'] == row['country']].iloc[0]['end_md_1']\n",
    "    start_md2 = df_events.loc[df_events['country'] == row['country']].iloc[0]['start_md_2']\n",
    "    \n",
    "    for week in zip(row['volume_weekly_total'].index,row['volume_weekly_total'].values,row['volume_percent_weekly_total'].values):\n",
    "        \n",
    "        entry = {}\n",
    "\n",
    "        entry['country'] = row['country']\n",
    "        entry['category'] = row['category']\n",
    "        \n",
    "\n",
    "        if week[0] in weeks_2020:\n",
    "            date = pd.to_datetime(week[0])\n",
    "\n",
    "            if type(start_md2)!=pd._libs.tslibs.nattype.NaTType and date > start_md2:\n",
    "                continue\n",
    "\n",
    "            entry['k'] = math.floor(((date - start_md).days +7) / 7)\n",
    "            entry['volume_total'] = week[1]\n",
    "            entry['volume_percent'] = week[2]\n",
    "            entry['year'] = '2020'\n",
    "            l.append(entry)\n",
    "\n",
    "        elif week[0] in weeks_2019:\n",
    "            date = pd.to_datetime(weeks_2020[weeks_2019.index(week[0])])\n",
    "            \n",
    "            if type(start_md2)!=pd._libs.tslibs.nattype.NaTType and date > start_md2:\n",
    "                continue\n",
    "\n",
    "            entry['k'] = math.floor(((date - start_md).days +7) / 7)\n",
    "            entry['volume_total'] = week[1]\n",
    "            entry['volume_percent'] = week[2]\n",
    "            entry['year'] = '2019'\n",
    "            l.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(l)\n",
    "df = df.loc[(df['k'] >= -30) & (df['k'] <= 30)]\n",
    "df = df.loc[(df['country'].isin(list(full_names.keys())))]\n",
    "df['intervention_flag'] = df['k'].apply(lambda x: 1 if x >= 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = list(df['category'].unique())\n",
    "k = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df.loc[(df['k'] >= -k) & (df['k'] <= k)].copy()\n",
    "df_temp['volume_total'] = df_temp['volume_total'].apply(np.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries_list = []\n",
    "\n",
    "for name, group in df_temp.groupby(['country','category']):\n",
    "    entry = {}\n",
    "    \n",
    "    mod = smf.ols(generate_equation('Quadratic'), data = group)\n",
    "    res = mod.fit(cov_type='hc0')\n",
    "    \n",
    "    entry['country'] = name[0]\n",
    "    entry['category'] = name[1]\n",
    "    \n",
    "    entry['alpha'] = res.params['intervention_flag:year[T.2020]']\n",
    "    entry['ste'] = res.bse['intervention_flag:year[T.2020]']\n",
    "    entry['pval'] = res.pvalues['intervention_flag:year[T.2020]']\n",
    "    entry['r2'] = res.rsquared\n",
    "    \n",
    "    entries_list.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.DataFrame(entries_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode 1 &\n",
      "0.34[0.11], 0.9 &\n",
      "0.46[0.13], 0.9 &\n",
      "0.57[0.1], 0.87 &\n",
      "0.43[0.12], 0.77 &\n",
      "0.29[0.08], 0.77 &\n",
      "0.84[0.13], 0.9 &\n",
      "0.73[0.15], 0.81 &\n",
      "0.78[0.14], 0.94 &\n",
      "1.03[0.12], 0.95 &\n",
      "0.77[0.16], 0.87 &\n",
      "0.58[0.11], 0.93 &\n",
      "0.6[0.08], 0.91\n",
      "\\\\\n",
      "Mode 2 &\n",
      "0.78[0.12], 0.9 &\n",
      "0.7[0.92], 0.93 &\n",
      "0.97[0.13], 0.95 &\n",
      "0.15[0.38], 0.85 &\n",
      "1.05[0.32], 0.9 &\n",
      "-0.09[0.23], 0.66 &\n",
      "0.96[0.35], 0.57 &\n",
      "0.37[0.26], 0.86 &\n",
      "0.37[0.15], 0.24 &\n",
      "0.95[0.16], 0.7 &\n",
      "0.4[0.3], 0.65 &\n",
      "1.11[0.08], 0.96\n",
      "\\\\\n",
      "Mode 3 &\n",
      "-0.78[0.15], 0.86 &\n",
      "-0.23[0.17], 0.88 &\n",
      "-0.68[0.17], 0.87 &\n",
      "-0.98[0.21], 0.84 &\n",
      "-0.7[0.19], 0.75 &\n",
      "-1.65[0.23], 0.93 &\n",
      "-1.7[0.19], 0.92 &\n",
      "-0.95[0.18], 0.84 &\n",
      "-0.49[0.15], 0.97 &\n",
      "-1.45[0.26], 0.88 &\n",
      "-0.54[0.15], 0.93 &\n",
      "-0.39[0.16], 0.82\n",
      "\\\\\n",
      "Mode 4 &\n",
      "0.1[0.17], 0.7 &\n",
      "0.16[0.13], 0.85 &\n",
      "0.24[0.11], 0.97 &\n",
      "0.44[0.21], 0.7 &\n",
      "0.19[0.24], 0.55 &\n",
      "-0.25[0.21], 0.75 &\n",
      "-0.58[0.37], 0.77 &\n",
      "0.92[0.29], 0.87 &\n",
      "-0.36[0.18], 0.92 &\n",
      "-0.6[0.21], 0.72 &\n",
      "-0.11[0.25], 0.49 &\n",
      "-0.06[0.08], 0.84\n",
      "\\\\\n"
     ]
    }
   ],
   "source": [
    "for name, group in df_res.groupby(['category']):\n",
    "    print(name+' &')\n",
    "    c=0\n",
    "    for name1, group1 in group.groupby(['country']):\n",
    "        c+=1\n",
    "        if c ==12:\n",
    "            print(str(round(group1['alpha'].values[0],2))+ '['+str(round(group1['ste'].values[0],2))+\n",
    "              '], '+str(round(group1['r2'].values[0],2)))\n",
    "        else:\n",
    "            print(str(round(group1['alpha'].values[0],2))+ '['+str(round(group1['ste'].values[0],2))+\n",
    "              '], '+str(round(group1['r2'].values[0],2))+' &')\n",
    "    print('\\\\\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
